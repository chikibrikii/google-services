{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FL_DATE',\n",
       " 'UNIQUE_CARRIER',\n",
       " 'AIRLINE_ID',\n",
       " 'CARRIER',\n",
       " 'TAIL_NUM',\n",
       " 'FL_NUM',\n",
       " 'ORIGIN_AIRPORT_ID',\n",
       " 'ORIGIN_AIRPORT_SEQ_ID',\n",
       " 'ORIGIN_CITY_MARKET_ID',\n",
       " 'ORIGIN',\n",
       " 'ORIGIN_CITY_NAME',\n",
       " 'ORIGIN_STATE_ABR',\n",
       " 'ORIGIN_STATE_FIPS',\n",
       " 'ORIGIN_STATE_NM',\n",
       " 'ORIGIN_WAC',\n",
       " 'DEST_AIRPORT_ID',\n",
       " 'DEST_AIRPORT_SEQ_ID',\n",
       " 'DEST_CITY_MARKET_ID',\n",
       " 'DEST',\n",
       " 'DEST_CITY_NAME',\n",
       " 'DEST_STATE_ABR',\n",
       " 'DEST_STATE_FIPS',\n",
       " 'DEST_STATE_NM',\n",
       " 'DEST_WAC',\n",
       " 'CRS_DEP_TIME',\n",
       " 'DEP_TIME',\n",
       " 'DEP_DELAY',\n",
       " 'DEP_DELAY_NEW',\n",
       " 'DEP_DEL15',\n",
       " 'DEP_DELAY_GROUP',\n",
       " 'DEP_TIME_BLK',\n",
       " 'TAXI_OUT',\n",
       " 'WHEELS_OFF',\n",
       " 'WHEELS_ON',\n",
       " 'TAXI_IN',\n",
       " 'CRS_ARR_TIME',\n",
       " 'ARR_TIME',\n",
       " 'ARR_DELAY',\n",
       " 'ARR_DELAY_NEW',\n",
       " 'ARR_DEL15',\n",
       " 'ARR_DELAY_GROUP',\n",
       " 'ARR_TIME_BLK',\n",
       " 'CANCELLED',\n",
       " 'DIVERTED',\n",
       " 'CRS_ELAPSED_TIME',\n",
       " 'ACTUAL_ELAPSED_TIME',\n",
       " 'AIR_TIME',\n",
       " 'FLIGHTS',\n",
       " 'DISTANCE',\n",
       " 'DISTANCE_GROUP',\n",
       " 'Unnamed: 50',\n",
       " 'AIRPORT_NAME',\n",
       " 'CARRIER_HIST',\n",
       " 'AIR_TIME_HOURS',\n",
       " 'ACTUAL_DEP_DELAY',\n",
       " 'ACTUAL_ARR_DELAY']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing, cross_validation\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# source directory path.\n",
    "src_dir = r\"C:\\Users\\chsoon\\Desktop\\airline_case\\Monthly Data\"\n",
    "\n",
    "# create list of each file directory.\n",
    "all_files = glob.glob(src_dir + \"/*.csv\")\n",
    "\n",
    "# concatenate all files into single dataframe.\n",
    "main_df = pd.DataFrame()\n",
    "main_list = []\n",
    "for file in all_files:\n",
    "    df = pd.read_csv(file, index_col=None, header=0)\n",
    "    main_list.append(df)\n",
    "main_df = pd.concat(main_list)\n",
    "\n",
    "# lookup tables paths.\n",
    "airport_id_dir = r\"C:\\Users\\chsoon\\Desktop\\airline_case\\Lookup Tables\\L_AIRPORT_ID.csv\"\n",
    "carrier_hist_dir = r\"C:\\Users\\chsoon\\Desktop\\airline_case\\Lookup Tables\\L_CARRIER_HISTORY.csv\"\n",
    "\n",
    "# create lookup table dataframes.\n",
    "airport_id_df = pd.read_csv(airport_id_dir)\n",
    "carrier_hist_df = pd.read_csv(carrier_hist_dir)\n",
    "\n",
    "# merge all dataframes on airport id, unique carrier name. \n",
    "airport_id_df.rename(columns={'Code':'ORIGIN_AIRPORT_ID', 'Description':'AIRPORT_NAME'}, inplace=True)\n",
    "main_df = pd.merge(main_df, airport_id_df, on='ORIGIN_AIRPORT_ID')\n",
    "carrier_hist_df.rename(columns={'Code':'UNIQUE_CARRIER', 'Description':'CARRIER_HIST'}, inplace=True)\n",
    "main_df = pd.merge(main_df, carrier_hist_df, on='UNIQUE_CARRIER')\n",
    "\n",
    "# create new columns\n",
    "# main_df[\"AIR_TIME_HOURS\"] = main_df[\"AIR_TIME\"] / 60\n",
    "main_df['ACTUAL_DEP_DELAY'] = main_df['DEP_DELAY'] > 0\n",
    "main_df['ACTUAL_ARR_DELAY'] = main_df['ARR_DELAY'] > 0\n",
    "\n",
    "main_df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  CARRIER_HIST  FLIGHTS\n",
      "0             Southwest Airlines Co. (1979 - )  1174633\n",
      "1               Delta Air Lines Inc. (1960 - )   800375\n",
      "2    Atlantic Southeast Airlines (1993 - 2011)   686021\n",
      "3           ExpressJet Airlines Inc. (2012 - )   686021\n",
      "4              SkyWest Airlines Inc. (2003 - )   613030\n",
      "5             American Airlines Inc. (1960 - )   537697\n",
      "6              United Air Lines Inc. (1960 - )   493528\n",
      "7                          USAir (1988 - 1997)   414665\n",
      "8                US Airways Inc. (1997 - 2015)   414665\n",
      "9               Simmons Airlines (1991 - 1998)   392701\n",
      "10  American Eagle Airlines Inc. (1998 - 2014)   392701\n",
      "11                         Envoy Air (2014 - )   392701\n",
      "12                   JetBlue Airways (2000 - )   249693\n",
      "13              Alaska Airlines Inc. (1960 - )   160257\n",
      "14            Frontier Airlines Inc. (1994 - )    85474\n",
      "15   AirTran Airways Corporation (1994 - 2014)    79495\n",
      "16        Frontier Airlines Inc. (1960 - 1986)    79495\n",
      "17            Hawaiian Airlines Inc. (1960 - )    74732\n",
      "18                    Virgin America (2007 - )    57510\n",
      "19                 Aces Airlines (1992 - 2003)    57510\n"
     ]
    }
   ],
   "source": [
    "flights_series = main_df.groupby('CARRIER_HIST',as_index=True).FLIGHTS.value_counts().sort_values(ascending=False)\n",
    "\n",
    "label = []\n",
    "count = []\n",
    "for i in flights_series.index:\n",
    "    label.append(i[0])\n",
    "    count.append(flights_series[i])\n",
    "    \n",
    "sub_df = pd.DataFrame({'CARRIER_HIST':label, 'FLIGHTS':count})\n",
    "print sub_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main_df[main_df.CANCELLED == 1].sum().groupby('CARRIER_HIST').sort_values(ascending=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'D', 'U', 'A', 'U', 'U', 'E', 'A', 'S', 'J', 'A', 'S', 'E', 'A', 'V', 'A', 'F', 'A', 'F', 'H']\n"
     ]
    }
   ],
   "source": [
    "airtime_series = main_df.groupby('CARRIER_HIST', as_index=True).AIR_TIME.sum().sort_values(ascending=False)\n",
    "label = []\n",
    "count = []\n",
    "for i in airtime_series.index:\n",
    "    label.append(i[0])\n",
    "    count.append(airtime_series[i])\n",
    "    \n",
    "bub_df = pd.DataFrame({'CARRIER_HIST':label, 'AIR_TIME':count})\n",
    "\n",
    "combine_df = pd.merge(sub_df, bub_df, on='CARRIER_HIST')\n",
    "print label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['FL_NUMBER'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8ffa58c9e1bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m               \u001b[1;34m'ORIGIN_AIRPORT_ID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m               \u001b[1;34m'ORIGIN_AIRPORT_SEQ_ID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m               'ORIGIN_CITY_MARKET_ID'], 1, inplace=True)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\chsoon\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[0;32m   1875\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1876\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1877\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1878\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1879\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\chsoon\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas\\indexes\\base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   3049\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3050\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[1;32m-> 3051\u001b[1;33m                                  labels[mask])\n\u001b[0m\u001b[0;32m   3052\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3053\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: labels ['FL_NUMBER'] not contained in axis"
     ]
    }
   ],
   "source": [
    "# drop all date and id fields.\n",
    "main_df.drop(['FL_DATE',\n",
    "              'AIRLINE_ID',\n",
    "              'FL_NUMBER',\n",
    "              'DEST_AIRPORT_ID',\n",
    "              'DEST_AIRPORT_SEQ_ID',\n",
    "              'DEST_CITY_MARKET_ID',\n",
    "              'ORIGIN_AIRPORT_ID',\n",
    "              'ORIGIN_AIRPORT_SEQ_ID',\n",
    "              'ORIGIN_CITY_MARKET_ID'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert all values to numeric type, if not int64 or float.\n",
    "main_df.convert_objects(convert_numeric=True)\n",
    "main_df.fillna(0, inplace=True)\n",
    "\n",
    "# function to handle non-numeric data.\n",
    "def handle_non_numeric_data(df):\n",
    "    columns = df.columns.values\n",
    "    \n",
    "    for column in columns:\n",
    "        text_digit_vals = {}  # empty dict of text and unique digits.\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "        \n",
    "        if df[column].dtype != np.int64 and df[column].dtype != float:\n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents)\n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x += 1        \n",
    "            df[column] = list(map(convert_to_int, df[column]))\n",
    "        \n",
    "    return df\n",
    "\n",
    "main_df = handle_non_numeric_data(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(main_df[\"DISTANCE\"], main_df[\"ARR_DELAY\"])\n",
    "plt.ylabel('Arrival Delays')\n",
    "plt.xlabel('Distance (miles)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(main_df[\"DISTANCE\"], main_df[\"AIR_TIME_MINS\"])\n",
    "plt.xlabel('Distance (miles)')\n",
    "plt.ylabel('Airtime (mins)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_df[\"AIR_TIME_MINS\"] = main_df[\"AIR_TIME\"] / 60\n",
    "plt.scatter(main_df[\"DISTANCE\"], main_df[\"AIR_TIME_MINS\"])\n",
    "plt.ylabel('Distance')\n",
    "plt.xlabel('Airtime (mins)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop all date and id fields.\n",
    "main_df.drop(['FL_DATE',\n",
    "              'AIRLINE_ID', \n",
    "              'DEST_AIRPORT_ID',\n",
    "              'DEST_AIRPORT_SEQ_ID',\n",
    "              'DEST_CITY_MARKET_ID',\n",
    "              'ORIGIN_AIRPORT_ID',\n",
    "              'ORIGIN_AIRPORT_SEQ_ID',\n",
    "              'ORIGIN_CITY_MARKET_ID'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to handle non-numeric data.\n",
    "def handle_non_numeric_data(df):\n",
    "    columns = df.columns.values\n",
    "    \n",
    "    for column in columns:\n",
    "        text_digit_vals = {}  # empty dict of text and unique digits.\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "        \n",
    "        if df[column].dtype != np.int64 and df[column].dtype != float:\n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents)\n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x += 1        \n",
    "            df[column] = list(map(convert_to_int, df[column]))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_df = handle_non_numeric_data(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(main_df[\"DISTANCE\"], main_df[\"DEP_DELAY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess and scale main data frame.\n",
    "main_df = preprocessing.scale(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train classifier. Do not need cross validation, as it is clustering.\n",
    "clf = KMeans(n_clusters=3)\n",
    "clf.fit(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define classifer.\n",
    "clf = KMeans(n_clusters=4)\n",
    "clf.fit()\n",
    "\n",
    "#access some of the attributes after fitting.\n",
    "centroids = clf.cluster_centers_\n",
    "labels = clf.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run kMeans on main dataframe.\n",
    "\n",
    "\n",
    "# feature extraction \n",
    "\n",
    "\n",
    "# split cluster data set into training, cross-validation and test.\n",
    "\n",
    "\n",
    "\n",
    "# run SVM on each cluster.\n",
    "\n",
    "\n",
    "\n",
    "# reference lookup tables and append descriptions for results. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
